---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app ollama
  namespace: ai
spec:
  chartRef:
    kind: OCIRepository
    name: *app
  interval: 1h
  values:
    controllers:
      ollama:
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          app:
            image:
              repository: docker.io/ollama/ollama
              tag: 0.13.5
            env:
              TZ: ${TIMEZONE}
              OLLAMA_HOST: 0.0.0.0
              OLLAMA_ORIGINS: "*"
              OLLAMA_MODELS: /models
              OLLAMA_KEEP_ALIVE: 24h
              OLLAMA_NUM_PARALLEL: 2
              OLLAMA_MAX_LOADED_MODELS: 1
            resources:
              requests:
                cpu: 200m
                memory: 1Gi
                nvidia.com/gpu: 1
              limits:
                memory: 12Gi
                nvidia.com/gpu: 1
    defaultPodOptions:
      nodeSelector:
        nvidia.com/gpu.present: "true"
      tolerations:
        - key: sku
          operator: Equal
          value: gpu
          effect: NoSchedule
      runtimeClassName: nvidia

    service:
      app:
        type: LoadBalancer
        annotations:
          lbipam.cilium.io/ips: "10.0.30.44"
        ports:
          http:
            port: 11434

    persistence:
      models:
        existingClaim: ollama
        globalMounts:
          - path: /models

      dev:
        type: hostPath
        hostPath: /dev/dri
        globalMounts:
          - readOnly: true
